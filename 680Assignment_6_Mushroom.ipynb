{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                       False\n",
       "cap-shape                   False\n",
       "cap-surface                 False\n",
       "cap-color                   False\n",
       "bruises                     False\n",
       "odor                        False\n",
       "gill-attachment             False\n",
       "gill-spacing                False\n",
       "gill-size                   False\n",
       "gill-color                  False\n",
       "stalk-shape                 False\n",
       "stalk-root                   True\n",
       "stalk-surface-above-ring    False\n",
       "stalk-surface-below-ring    False\n",
       "stalk-color-above-ring      False\n",
       "stalk-color-below-ring      False\n",
       "veil-type                   False\n",
       "veil-color                  False\n",
       "ring-number                 False\n",
       "ring-type                   False\n",
       "spore-print-color           False\n",
       "population                  False\n",
       "habitat                     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the mushroom project. The purpose of this assignment is to predict if a mushroom is poisonous or not. \n",
    "# The methods I will be using in this assignment are mainly KNN and PCA algorithms\n",
    "# First, let's import mushroom dataset and adds the columns name to it\n",
    "#Common import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import the data set\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "#Add column names\n",
    "mushrooms =  pd.read_csv(url, names = ['class', 'cap-shape', 'cap-surface', \n",
    "                                       'cap-color', 'bruises', 'odor', 'gill-attachment', \n",
    "                                       'gill-spacing', 'gill-size', 'gill-color', \n",
    "                                       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
    "                                       'stalk-surface-below-ring', 'stalk-color-above-ring', \n",
    "                                       'stalk-color-below-ring', 'veil-type', 'veil-color', \n",
    "                                       'ring-number', 'ring-type', 'spore-print-color', \n",
    "                                       'population', 'habitat'], na_values = \"?\")\n",
    "# check if there is a column contains a null value, there has a columns contains \"nan\" value\n",
    "mushrooms.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ['p' 'e']\n",
      "cap-shape ['x' 'b' 's' 'f' 'k' 'c']\n",
      "cap-surface ['s' 'y' 'f' 'g']\n",
      "cap-color ['n' 'y' 'w' 'g' 'e' 'p' 'b' 'u' 'c' 'r']\n",
      "bruises ['t' 'f']\n",
      "odor ['p' 'a' 'l' 'n' 'f' 'c' 'y' 's' 'm']\n",
      "gill-attachment ['f' 'a']\n",
      "gill-spacing ['c' 'w']\n",
      "gill-size ['n' 'b']\n",
      "gill-color ['k' 'n' 'g' 'p' 'w' 'h' 'u' 'e' 'b' 'r' 'y' 'o']\n",
      "stalk-shape ['e' 't']\n",
      "stalk-root ['e' 'c' 'b' 'r' nan]\n",
      "stalk-surface-above-ring ['s' 'f' 'k' 'y']\n",
      "stalk-surface-below-ring ['s' 'f' 'y' 'k']\n",
      "stalk-color-above-ring ['w' 'g' 'p' 'n' 'b' 'e' 'o' 'c' 'y']\n",
      "stalk-color-below-ring ['w' 'p' 'g' 'b' 'n' 'e' 'y' 'o' 'c']\n",
      "veil-type ['p']\n",
      "veil-color ['w' 'n' 'o' 'y']\n",
      "ring-number ['o' 't' 'n']\n",
      "ring-type ['p' 'e' 'l' 'f' 'n']\n",
      "spore-print-color ['k' 'n' 'u' 'h' 'w' 'r' 'o' 'y' 'b']\n",
      "population ['s' 'n' 'a' 'v' 'y' 'c']\n",
      "habitat ['u' 'g' 'm' 'd' 'p' 'w' 'l']\n"
     ]
    }
   ],
   "source": [
    "# See if any columns have any non-sense or null values.\n",
    "# From below noticed that 'stalk-root' column contains 'nan' value.\n",
    "for i in mushrooms.columns:\n",
    "    print(i,mushrooms[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# remove poisonous target feature \n",
    "m_notarget = mushrooms.drop(['class'], axis=1)\n",
    "\n",
    "# instead of using train_test_split, we are here manually split the data into x_train,y_train,x_test and y_test\n",
    "# y-train is the non-null stalk-root feature rows\n",
    "y_train = mushrooms['stalk-root'][mushrooms['stalk-root'].notnull()]\n",
    "y_train = y_train.to_frame()\n",
    "\n",
    "# x_train is the non-null rows of all the other columns in the same indices of non-null stalk root feature rows\n",
    "df_other_columns = m_notarget.drop('stalk-root', axis=1)\n",
    "x_train = df_other_columns.loc[y_train.index]\n",
    "\n",
    "#Set columns with nan as response\n",
    "# y_pred is the null stalk-root feature rows that we'r trying to impute\n",
    "y_pred  = mushrooms['stalk-root'][mushrooms['stalk-root'].isnull()]\n",
    "y_pred = pd.DataFrame(y_pred , columns = ['stalk-root'])\n",
    "\n",
    "# x_test is the non-null rows of all the other columns in the same indices of the null stalk root feature rows\n",
    "x_test = df_other_columns.loc[y_pred.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Instantiate an object of the OneHotEncoder with drop parameter set to first\n",
    "cat_encoder = OneHotEncoder(drop = 'first', handle_unknown = 'ignore')\n",
    "\n",
    "#Call the fit_transform() method and pass categorical data, data_cat\n",
    "train_feature_encoder = cat_encoder.fit_transform(x_train).toarray()\n",
    "test_feature_encoder = cat_encoder.transform(x_test).toarray()\n",
    "\n",
    "#Call labelencode method to response data \n",
    "response_label = LabelEncoder()\n",
    "y_train = y_train.values.flatten() \n",
    "train_response_encoder = response_label.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train knn model\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(train_feature_encoder,train_response_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have the knn model to make a prediction about the missing values\n",
    "predicted = knn.predict(test_feature_encoder)\n",
    "predicted = predicted.ravel()\n",
    "\n",
    "#Use inverse_transform() function of ordinal encoder to get the categorical \n",
    "#values back from the numerical dtype\n",
    "stalkroot_categorical = response_label.inverse_transform(predicted)\n",
    "\n",
    "#Replace nan with prediction values\n",
    "df_stalkrootpred = pd.DataFrame(stalkroot_categorical, columns = ['stalk-root'])\n",
    "df_stalkrootpred.index = y_pred.index\n",
    "\n",
    "#The complete column of stalk-root is now without nan value\n",
    "y_train = pd.DataFrame(y_train,columns = ['stalk-root'])\n",
    "df_stalk_root = pd.concat([y_train,df_stalkrootpred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>stalk-root</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>s</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class stalk-root cap-shape cap-surface cap-color bruises odor  \\\n",
       "0     p          e         x           s         n       t    p   \n",
       "1     e          c         x           s         y       t    a   \n",
       "2     e          c         b           s         w       t    l   \n",
       "3     p          e         x           y         w       t    p   \n",
       "4     e          e         x           s         g       f    n   \n",
       "5     e          c         x           y         y       t    a   \n",
       "6     e          c         b           s         w       t    a   \n",
       "7     e          c         b           y         w       t    l   \n",
       "8     p          e         x           y         w       t    p   \n",
       "9     e          c         b           s         y       t    a   \n",
       "\n",
       "  gill-attachment gill-spacing gill-size  ... stalk-surface-below-ring  \\\n",
       "0               f            c         n  ...                        s   \n",
       "1               f            c         b  ...                        s   \n",
       "2               f            c         b  ...                        s   \n",
       "3               f            c         n  ...                        s   \n",
       "4               f            w         b  ...                        s   \n",
       "5               f            c         b  ...                        s   \n",
       "6               f            c         b  ...                        s   \n",
       "7               f            c         b  ...                        s   \n",
       "8               f            c         n  ...                        s   \n",
       "9               f            c         b  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "5                      w                      w         p          w   \n",
       "6                      w                      w         p          w   \n",
       "7                      w                      w         p          w   \n",
       "8                      w                      w         p          w   \n",
       "9                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "5           o         p                 k          n       g  \n",
       "6           o         p                 k          n       m  \n",
       "7           o         p                 n          s       m  \n",
       "8           o         p                 k          v       g  \n",
       "9           o         p                 k          s       m  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create full feature dataset by concat x_train and x_test\n",
    "df_x = pd.concat([x_train, x_test])\n",
    "\n",
    "#Put the complete 'stalk-root' column back to the orginal feature dataset\n",
    "df_stalk_root.index = df_x.index\n",
    "df_org = pd.concat([df_stalk_root,df_x],axis =1)\n",
    "\n",
    "#Add back dropped target feature,'class' column\n",
    "df_class = pd.DataFrame(mushrooms['class'])\n",
    "df = pd.concat([df_class,df_org],axis =1)\n",
    "\n",
    "#Print the first 10 rows of new complete dataset with no any nan\n",
    "missing_values = df.head(10)\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question_1: \n",
    "Yes,if one-hot encoded the response data instead, it's still able to train the KNN model.\n",
    "The integer encoding is insufficient for categorical variables where there is no such \n",
    "ordinal relationship.In practice, allowing the version to assume natural class ordering \n",
    "and using this encoding may result in poor overall performance or unexpected results \n",
    "(predictions halfway among classes).In this situation, a one-time encoding of the\n",
    "integer representation could be used. The integer encoded variable is removed for \n",
    "each specified integer value, and a new binary variable is supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common import and split updated dataset without any nan value\n",
    "from sklearn.model_selection import train_test_split\n",
    "x=df.iloc[:,df.columns!='class']\n",
    "y=df.iloc[:,0]\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate an object of the OneHotEncoder with drop parameter set to first\n",
    "onehot_encoder = OneHotEncoder(drop = 'first', handle_unknown = 'ignore')\n",
    "\n",
    "#Call the fit_transform() method and pass categorical data, data_cat\n",
    "train_feature_encoder = onehot_encoder.fit_transform(x_train).toarray()\n",
    "test_feature_encoder = onehot_encoder.transform(x_test).toarray()\n",
    "\n",
    "#Call the LabelEncoder() method\n",
    "response_label = LabelEncoder()\n",
    "train_response_encoder = response_label.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question_2:\n",
    "No, you cannot train both models on RandomForestClassifier and logistic regression algorithms if you one-hot encoded the response data.One-hot coding creates a dummy variable trap because the final results of one variable can be easily predicted using the remaining variables. The dummy variable trap is a situation in which variables are highly correlated with each other. The dummy variable trap leads to a problem called multicollinearity. Multicollinearity occurs, in which there is a dependency between the independent characteristics. Multicollinearity is a serious problem in devices that extract knowledge from models.Here I almost reveal how the multicollinearity problem occurs after the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common import and train the random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(train_feature_encoder,train_response_encoder)\n",
    "rf_pred = rf.predict(test_feature_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver=\"lbfgs\")\n",
    "clf.fit(train_feature_encoder,train_response_encoder)\n",
    "clf_pred = clf.predict(test_feature_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478 ms ± 33 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(train_feature_encoder,train_response_encoder)\n",
    "rf_pred = rf.predict(test_feature_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.6 ms ± 15.6 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver=\"lbfgs\")\n",
    "clf.fit(train_feature_encoder,train_response_encoder)\n",
    "clf_pred = clf.predict(test_feature_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning Categorical value of random forest model\n",
    "imputed_rf = rf_pred.reshape(-1, 1)\n",
    "categorical_rfpred = response_label.inverse_transform(imputed_rf.ravel())\n",
    "# Returning Categorical value of logistic regression model\n",
    "imputed_clf = clf_pred.reshape(-1, 1)\n",
    "categorical_clfpred = response_label.inverse_transform(imputed_clf.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           e       1.00      1.00      1.00       843\n",
      "           p       1.00      1.00      1.00       782\n",
      "\n",
      "    accuracy                           1.00      1625\n",
      "   macro avg       1.00      1.00      1.00      1625\n",
      "weighted avg       1.00      1.00      1.00      1625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print classification report of random forest model\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(categorical_rfpred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           e       1.00      1.00      1.00       843\n",
      "           p       1.00      1.00      1.00       782\n",
      "\n",
      "    accuracy                           1.00      1625\n",
      "   macro avg       1.00      1.00      1.00      1625\n",
      "weighted avg       1.00      1.00      1.00      1625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print classification report of logistic regression model\n",
    "print(classification_report(categorical_clfpred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both random forest and logistic regression performed very efficiently in providing good predictions. Accuracy, precision and recall all 100%. Our large set of predictors we have given is very good at predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18059977 0.10526527 0.08823667 0.05326606 0.04504662 0.04062511\n",
      " 0.03645102 0.03125304 0.02663138 0.02524412 0.02312577 0.02174843\n",
      " 0.01979873 0.01835232 0.01818592 0.01747714 0.01567503 0.01492226\n",
      " 0.01414152 0.01285241 0.01261076 0.01156224 0.01073068 0.01014324\n",
      " 0.00995045 0.00970005 0.00919718 0.00906698 0.0082216  0.00802871\n",
      " 0.00702482 0.00691255 0.00652527 0.00554139 0.0054683  0.00525617\n",
      " 0.00460621 0.00430221]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# 95% of variance\n",
    "pca = PCA(n_components = 0.95)\n",
    "x_train_pca = pca.fit_transform(train_feature_encoder)\n",
    "x_test_pca = pca.transform(test_feature_encoder)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape:    (1625, 94)\n",
      "transformed shape: (1625, 38)\n"
     ]
    }
   ],
   "source": [
    "#Print out orginal data shape and transformed data shape after pca\n",
    "print(\"original shape:   \", test_feature_encoder.shape)\n",
    "print(\"transformed shape:\", x_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60%\n"
     ]
    }
   ],
   "source": [
    "#Calculate how many percentage have reduced of dimensions \n",
    "reduced = np.subtract(test_feature_encoder.shape[1], x_test_pca.shape[1])\n",
    "number = reduced/(test_feature_encoder.shape[1])\n",
    "# Print the result of how many percentage have reduced of dimensions \n",
    "print(f\"{number:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is how many dimensions left with after reducing dimensionality\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the Random Forest Classifier on reduced dataset\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(x_train_pca,train_response_encoder)\n",
    "rf_pred_pca = rf.predict(x_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the Logistic Regression on reduced dataset\n",
    "clf = LogisticRegression(solver=\"lbfgs\")\n",
    "clf.fit(x_train_pca,train_response_encoder)\n",
    "clf_pred = clf.predict(x_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.41 s ± 741 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(x_train_pca,train_response_encoder)\n",
    "rf_pred_pca = rf.predict(x_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.9 ms ± 4.38 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "clf = LogisticRegression(solver=\"lbfgs\")\n",
    "clf.fit(x_train_pca,train_response_encoder)\n",
    "clf_pred = clf.predict(x_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returning Categorical value of random forest model on the reduced dataset\n",
    "pca_rf = rf_pred_pca.reshape(-1, 1)\n",
    "pca_rfpred = response_label.inverse_transform(pca_rf.ravel())\n",
    "#Returning Categorical value of logistic regression model on the reduced dataset\n",
    "pca_clf = clf_pred.reshape(-1, 1)\n",
    "pca_clfpred = response_label.inverse_transform(pca_clf.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           e       1.00      1.00      1.00       843\n",
      "           p       1.00      1.00      1.00       782\n",
      "\n",
      "    accuracy                           1.00      1625\n",
      "   macro avg       1.00      1.00      1.00      1625\n",
      "weighted avg       1.00      1.00      1.00      1625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print classification report of random forest model on reduced dataset \n",
    "print(classification_report(pca_rfpred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           e       0.99      0.99      0.99       845\n",
      "           p       0.99      0.99      0.99       780\n",
      "\n",
      "    accuracy                           0.99      1625\n",
      "   macro avg       0.99      0.99      0.99      1625\n",
      "weighted avg       0.99      0.99      0.99      1625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print classification report of logistic regression model on reduced dataset \n",
    "print(classification_report(pca_clfpred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of pca logistic regression : 0.9926153846153846\n",
      "Accuracy of pca random forest: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Confirm accuracy of prediction using logistic regression on reduced dataset \n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy of pca logistic regression :\", accuracy_score(y_test, pca_clfpred))\n",
    "# confirm accuracy of prediction using random forest model on reduced dataset \n",
    "print(\"Accuracy of pca random forest:\", accuracy_score(y_test, pca_rfpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                Item         Full Data    PCA Reduced\n",
      "Random Forest        Accuracy           1             1\n",
      "                     Precision          1             1\n",
      "                     Recall             1             1\n",
      "                     Time(ms)         433          2600\n",
      "Logistic Regression  Accuracy           1             0.99\n",
      "                     Precision          1             0.99\n",
      "                     Recall             1             0.99\n",
      "                     Time(ms)          81.7          46.1\n"
     ]
    }
   ],
   "source": [
    "#Common import \n",
    "from tabulate import tabulate\n",
    "#create tabulate table\n",
    "print(tabulate({'Model':['Random Forest', None,None,None,'Logistic Regression'], \n",
    "                'Item':['Accuracy', 'Precision','Recall','Time(ms)','Accuracy', \n",
    "                         'Precision','Recall','Time(ms)'], \n",
    "                 'Full Data':[1,1,1,433,1,1,1,81.7],\n",
    "                 'PCA Reduced':[1,1.00,1.00,2600,0.99,0.99,0.99,46.1]},\n",
    "               headers = ['Model', 'Item','Full Data','PCA Reduced'],tablefmt='plain'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For processing time, we can see logistic regression model takes plenty much less time than the random forest model on each full data and reduced data. Logistic regression is processed quicker on reduced data than on full data. Random forest processed slower on reduced data than full data.\n",
    "\n",
    "For accuracy, precision, and recall values, the random forest model is very properly estimated on each full data and reduced data. Logistic regression worked very properly on full data too, however on reduced data, all these values are still good with slightly(0.01) much less in contrast with random forest algorithm. Since all accuracy, precision, and recall values are either 100% or 99% from two different algorithm on both full and reduced data, there is no obvious evidence of overfitting. \n",
    "\n",
    "I can conclude that logistic regression processed a lot quicker than the random forest algorithm with the equal excellent accuracy, precision, and recall values that the random forest model produced on full data. However logistic regression algorithm produced slightly less good values on reduced data than the random forest model made. The random forest algorithm was superior and more accurate for mushroom dataset classification on both full data and reduced data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
